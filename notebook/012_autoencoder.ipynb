{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import os\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', 300)\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import create_save_folder, EarlyStopping\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "fm_path = create_save_folder('nb012')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class denoising_model(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(denoising_model,self).__init__()\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Linear(num_columns,256),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            nn.SiLU(True),\n",
    "            nn.Linear(256,128),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            nn.SiLU(True),\n",
    "        )\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Linear(128,256),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            nn.SiLU(True),\n",
    "            nn.Linear(256, num_columns),\n",
    "            # nn.BatchNorm1d(num_columns),\n",
    "            nn.SiLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class DataSet:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # noise = torch.randn(self.data.shape[1]).cuda()\n",
    "        # clean = self.data[index]\n",
    "        # dirty = self.data[index] + noise\n",
    "        # return clean, dirty\n",
    "        return self.data[index]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "with open('/home/yoshikawa/work/kaggle/OPVP/output/feature_model/20210824/0/train.pkl', 'rb') as f:\n",
    "    df_train = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train = df_train.drop(['row_id', 'target'], axis=1)\n",
    "for col in train.columns.to_list():\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "\n",
    "scales = train.drop([\"stock_id\"], axis = 1).columns.to_list()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[scales])\n",
    "train[scales] = scaler.transform(train[scales])\n",
    "le = LabelEncoder()\n",
    "le.fit(train[\"stock_id\"])\n",
    "train[\"stock_id\"] = le.transform(train[\"stock_id\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_data = torch.tensor(train.values.astype(np.float32)).cuda()\n",
    "train_data.shape[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=55)\n",
    "epochs = 1\n",
    "\n",
    "cv = 0\n",
    "models = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_data)):\n",
    "    print('fold: ', fold)\n",
    "    print('='*100)\n",
    "    train_dataset = DataSet(train_data[train_idx].cuda())\n",
    "    val_dataset = DataSet(train_data[val_idx].cuda())\n",
    "    train_loader = DataLoader(train_dataset, 4096, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, 4096)\n",
    "    \n",
    "    model = denoising_model(train_data.shape[1]).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    earlystopping = EarlyStopping(patience=10, verbose=True, path=fm_path+'/checkpoint.pth')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, val_loss = 0, 0\n",
    "\n",
    "        for j, data in enumerate(train_loader):\n",
    "            noise = torch.randn(data.shape).cuda()\n",
    "            dirty = data + noise\n",
    "            output = model(dirty)\n",
    "            loss = criterion(output, data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * data.shape[0]\n",
    "        \n",
    "        train_loss /= len(train_dataset)\n",
    "        \n",
    "        for j, data in enumerate(val_loader):\n",
    "            noise = torch.randn(data.shape).cuda()\n",
    "            dirty = data + noise\n",
    "            output = model(dirty)\n",
    "            loss = criterion(output, data)\n",
    "            val_loss += loss.item() * data.shape[0]\n",
    "        \n",
    "        val_loss /= len(val_dataset)\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(i+1, \" epoch - train_loss: \", round(train_loss, 4), \", val_loss: \", round(val_loss, 4))\n",
    "        earlystopping(val_loss, model)\n",
    "        if earlystopping.early_stop:\n",
    "            print(\"Early Stopping!!\")\n",
    "            break\n",
    "    cv += val_loss\n",
    "    model.load_state_dict(torch.load(fm_path+'/checkpoint.pth'))\n",
    "    models.append(model)\n",
    "cv /= 5\n",
    "print(\"cv: \", round(cv, 4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fold:  0\n",
      "====================================================================================================\n",
      "Validation loss decreased (inf --> 0.422317).  Saving model ...\n",
      "fold:  1\n",
      "====================================================================================================\n",
      "Validation loss decreased (inf --> 0.435681).  Saving model ...\n",
      "fold:  2\n",
      "====================================================================================================\n",
      "Validation loss decreased (inf --> 0.433549).  Saving model ...\n",
      "fold:  3\n",
      "====================================================================================================\n",
      "Validation loss decreased (inf --> 0.420706).  Saving model ...\n",
      "fold:  4\n",
      "====================================================================================================\n",
      "Validation loss decreased (inf --> 0.422224).  Saving model ...\n",
      "cv:  0.4269\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "output = torch.zeros((train_data.shape[0], 128))\n",
    "for i, model in enumerate(models):\n",
    "    # train_dataset = DataSet(train_data)\n",
    "    # train_loader = DataLoader(train_dataset, 4096, shuffle=False)\n",
    "    # for j, data in enumerate(train_loader):\n",
    "    output += model.encode(train_data).cpu() / 5\n",
    "    torch.save(model.state_dict(), fm_path+'/model-'+str(i))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[4.8065e-02, 1.1818e-01, 4.6098e-02,  ..., 1.7241e-01, 9.0036e-02,\n",
       "         2.3407e-01],\n",
       "        [1.6834e-01, 2.8846e-01, 4.4912e-01,  ..., 2.0677e-01, 3.2622e-03,\n",
       "         1.4922e-01],\n",
       "        [5.6044e-02, 2.6877e-01, 3.5047e-01,  ..., 1.4037e-01, 3.0234e-03,\n",
       "         1.3634e-01],\n",
       "        ...,\n",
       "        [7.4567e+00, 7.5820e+00, 9.1783e+00,  ..., 8.6905e+00, 7.7450e+00,\n",
       "         3.4075e+00],\n",
       "        [7.4372e+00, 7.5487e+00, 9.2856e+00,  ..., 8.6053e+00, 7.9176e+00,\n",
       "         2.9307e+00],\n",
       "        [7.3039e+00, 7.4992e+00, 9.4639e+00,  ..., 8.5865e+00, 7.2663e+00,\n",
       "         2.7058e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "output.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([428932, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df_output = pd.DataFrame(output.detach().numpy())\n",
    "df_output.columns = ['DAE_'+ str(i) for i in df_output.columns]\n",
    "df_output.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.concat([df_train, df_output], axis=1)\n",
    "pickle.dump(df, open(os.path.join(fm_path, \"train.pkl\"), 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "283baaf4ce8ec1279b6a1eb52777837c25a71c1c72f4c54d87f2b7711be4d242"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('kaggle': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}